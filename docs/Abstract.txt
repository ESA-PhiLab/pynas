Advancements in spaceborne edge computing has facilitated the incorporation of AI-powered chips into CubeSats, allowing for intelligent data handling and enhanced analytical capabilities with greater operational autonomy. This class of satellites face stringent energy and memory constraints, thus necessitating lightweight models which are often obtained by compression techniques. This paper addresses model compression by NAS to enable computational efficiency and balance between accuracy, size, and latency. More in detail, we design an evolutionary-based NAS framework for onbord processing and test its capabilities on the burned area segmentation test case. The proposed solution jointly optimizes network architecture and deployment for hardware-specific resource-constrained platforms. Additionally, hardware-awareness is introduced in the optimization loop for tailoring the network topology to the specific target edge computing chip. The resulting models, which has been desiged on CubeSat-class hardware, i.e. an NVIDIA Jetson AGX Orion and the Intel Movidious Myriad X, exhibits a memory footprint below 1 MB, outperforming handcrafted baselines in terms of latency (3Ã— faster) and maintain competitive miou; additionally enabling real-time, high-resolution inference in orbit.